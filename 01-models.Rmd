# Models

```{r setup, include = FALSE}
#| cache: false
# Packages
library(tidyverse)
library(knitr)
library(posterior)
library(ragg)
library(here)
library(scales)
library(bayestestR)
library(kableExtra)
library(memoise)
library(cachem)
library(ggh4x)
library(cmdstanr)
library(brms)

# Common options
source("_common.R")
cd <- cache_disk("memoise_cache", max_size = Inf)
```

Here we discuss the models. The code for estimating these models is in `models.R`. We submit that to our local HPC with SLURM scheduler with `submit.sh`. 

## Model 1

Model 1 is a two-level probabilistic multivariate meta-regression model that simultaneously predicts the health (e.g. Life satisfaction) and internet variables (e.g. internet adoption) from time, sex, and time by sex interactions. These regression coefficients are modelled as multivariate normal distributed over countries, age groups, and the country by age groups. The latter clustering was dropped from the mental health variables because of nonconvergence due to lack of variance in data ($\Sigma^\text{age:country} = 0$). The country-level covariance matrices are shared across the two outcomes so we can assess correlations between countries' intercepts and slopes over the two outcomes.

Because we are modelling meta-analytic estimates (GBD) and aggregated scores (GWP), we also incorporate the aggregates' standard errors in the model to weight the observations on their corresponding uncertainties. Due to nonconvergence, we set the SEs to zero for self-harm ($v = 0$).

$$
\begin{align}
y_i &\sim \text{Normal}(\mu^y_i, \sigma^{y2}v_i) \\
x_i &\sim \text{Normal}(\mu^x_i, \sigma^{x2}) \\ 
\mu^y_i &= \alpha^{y}_{0} + \beta^{y}_{0\text{country}[i]} + \gamma^{y}_{0\text{age}[i]} + \delta^{y}_{0\text{age:country}[i]} + \\ 
&(\alpha^{y}_{1} + \beta^{y}_{1\text{country}[i]} + \gamma^{y}_{1\text{age}[i]} + \delta^{y}_{1\text{age:country}[i]})\text{Time}_i + \\
&(\alpha^{y}_{2} + \beta^{y}_{2\text{country}[i]} + \gamma^{y}_{2\text{age}[i]} + \delta^{y}_{2\text{age:country}[i]})\text{Sex}_i + \\
&(\alpha^{y}_{3} + \beta^{y}_{3\text{country}[i]} + \gamma^{y}_{3\text{age}[i]} + \delta^{y}_{3\text{age:country}[i]})\text{Sex}_i \times \text{Time}_i \\
\mu^x_i &= \alpha^{x}_{0} + \beta^{x}_{0\text{country}[i]} + (\alpha^x_{1} + \beta^{x}_{1\text{country}[i]})\text{Time}_i \\
\pmb{\beta} &\sim MVN(\pmb{0}, \Sigma^\text{country}) \\
\pmb{\gamma} &\sim MVN(\pmb{0}, \Sigma^\text{age}) \\
\pmb{\delta} &\sim MVN(\pmb{0}, \Sigma^\text{age:country})
\end{align}
$$ {#eq-model1}

## Model 2

Model 2 was similar to Model 1, but the internet outcome was dropped, and the regression equation for outcomes expanded to include the lagged internet predictor and its two-way interactions

$$
\begin{align}
y_i &\sim \text{Normal}(\mu_i, \sigma^{y2}v_i) \\
\mu_i &= \alpha_{0} + \beta_{0\text{country}[i]} + \gamma_{0\text{age}[i]} + \delta_{0\text{age:country}[i]} + \\ 
&(\alpha_{1} + \beta_{1\text{country}[i]} + \gamma_{1\text{age}[i]} + \delta_{1\text{age:country}[i]})\text{Time}_i + \\
&(\alpha_{2} + \beta_{2\text{country}[i]} + \gamma_{2\text{age}[i]} + \delta_{2\text{age:country}[i]})\text{Sex}_i + \\
&(\alpha_{3} + \beta_{3\text{country}[i]} + \gamma_{3\text{age}[i]} + \delta_{3\text{age:country}[i]})\text{Sex}_i \times \text{Time}_i \\
&(\alpha_{4} + \beta_{4\text{country}[i]} + \gamma_{4\text{age}[i]} + \delta_{4\text{age:country}[i]})\text{Internet}^{\text{t-1}}_i \\
&(\alpha_{5} + \beta_{5\text{country}[i]} + \gamma_{5\text{age}[i]} + \delta_{5\text{age:country}[i]})\text{Sex}_i \times \text{Internet}^{\text{t-1}}_i \\
\pmb{\beta} &\sim MVN(\pmb{0}, \Sigma^\text{country}) \\
\pmb{\gamma} &\sim MVN(\pmb{0}, \Sigma^\text{age}) \\
\pmb{\delta} &\sim MVN(\pmb{0}, \Sigma^\text{age:country})
\end{align}
$$ {#eq-model2}

Where $\text{Internet}^{\text{t-1}}_i$ is the within-country centered 1-year-lagged internet user proportion (or mobile subscriptions).

## Model checking and parameters

Next, we display the population-level parameters of each model, along with their numerical HMC diagnostics (ESS and Rhat values).

```{r}
oo <- c(
  "Life_satisfaction", "Negative_experiences", "Positive_experiences",
  "Anxiety", "Depression", "Selfharm"
)
fits <- tibble(outcome = oo) %>% 
  mutate(outcome = fct_inorder(outcome))

# The files are huge and unwieldy to work with. We create smaller files for each by dropping samples of the age:country interaction random effects. It is then easier to post-process the models.
dir.create("models-small", FALSE)

replace_chain <- function(x) {
  x %>%
    select(
      -starts_with("r_1"),
      -starts_with("r_2"),
      -starts_with("r_3"),
      -starts_with("z_1"),
      -starts_with("z_2"),
      -starts_with("z_3"),
      -starts_with("r_age:country"),
      -starts_with("L_")
    )
}

replace_chain_all <- function(x) {
  if (!file.exists(str_glue("models-small/{x}"))) {
    message(x)
    out <- readRDS(str_glue("models/{x}"))
    out$fit@sim$samples <- map(1:4, ~replace_chain(out$fit@sim$samples[[.]]))
    saveRDS(out, str_glue("models-small/{x}"), compress = FALSE)
  }
}

walk(
  list.files("models"),
  ~replace_chain_all(.x)
)
```

### Parameters and diagnostics

Rhats should approach 1, and the latter should approach the number of hmc iterations. We first calculate these posterior summaries for each population level parameter for each outcome and model.

```{r model-diagnostics}
parameter_summary <- function(outcome, model) {
  path <- str_glue("models-small/brm-{outcome}-{model}.rds")
  as_draws_df(
    readRDS(path), 
    variable = c("^b_", "^sd_", "^cor_"), 
    regex = TRUE
  ) %>%
    summarise_draws(
      mean, sd,
      ~quantile2(., probs = c(.025, .5, .975)),
      pd = ~pd(as.numeric(.)), 
      samples = length, 
      default_convergence_measures()
    )
}
parameter_summary <- memoise(parameter_summary, cache = cd)

fits_parameters <- tibble(
  path = list.files("models-small/", pattern = ".rds$", full.names = FALSE)
) %>% 
  separate(path, c("brm", "outcome", "model"), sep = "-") %>% 
  select(-brm) %>% 
  mutate(outcome = factor(outcome, levels = oo)) %>% 
  arrange(outcome) %>% 
  mutate(model = str_extract(model, "[0-9]")) %>% 
  mutate(parameters = map2(outcome, model, ~parameter_summary(.x, .y))) %>% 
  unnest(parameters)
```

Then display them for each model

```{r model-1-diagnostics}
#| column: body-outset-right
#| label: tab-model1-diagnostic
#| tbl-cap: "HMC Diagnostics, Model 1 population-level regression coefficients and country-level (co)variance parameters."

parameter_table <- function(model) {
  x <- fits_parameters %>% 
    filter(model == {{model}}) %>% 
    select(-model)
  x %>% 
    kbl(
      caption = str_glue("Model {model}"),
      digits = c(0,0,2,2,2,2,2,2,0,2,0,0)
    ) %>%
    column_spec(
      10,
      color = "white",
      background = spec_color(
        log(x$rhat),
        direction = 1,
        option = "C",
        end = .6
      )
    ) %>%
    row_spec(0, bold = TRUE) %>% 
    kable_custom() %>% 
    scroll_box(height = "800px", width = "900px")
}
```

::: {.panel-tabset}

#### Model 1

```{r}
#| echo: false
parameter_table(1)
```

#### Model 2

```{r}
#| echo: false
parameter_table(2)
```

#### Model 3

```{r}
#| echo: false
parameter_table(3)
```

#### Model 4

```{r}
#| echo: false
parameter_table(4)
```

:::


### Scatterplots

Have the chains converged? Are there divergences?

For each model, we draw a scatterplot matrix of parameters with worst rhats. Browse these figures at `diagnostics/`

```{r}
# Function to draw a pairsplot of variables `v` of model in `path` 
pairsplot <- function(path, v) {
  if (!file.exists(str_glue("diagnostics/{basename(path)}.png"))) {
    x <- readRDS(here(path))
    agg_png(
      str_glue("diagnostics/{basename(path)}.png"),
      width = W*1.2, height = W*1.2, units = "in", res = 160
    )
    pairs(x$fit, pars = v)
    title(sub = path)
    dev.off()
  }
}

# Draw pairsplot for 10 worst rhats per model
fits_parameters %>% 
  group_by(outcome, model) %>% 
  arrange(outcome, model, desc(rhat)) %>% 
  slice(1:10) %>% 
  ungroup() %>% 
  group_by(outcome, model) %>% 
  summarise(v = list(variable)) %>% 
  mutate(path = str_glue("models-small/brm-{outcome}-{model}.rds")) %>% 
  ungroup() %>% 
  {walk2(.$path, .$v, ~pairsplot(.x, .y))}
```


### Posterior predictive checks

Do the models reproduce the observed data?

```{r ppcheck-density}
#| fig-height: 6
#| fig-width: 9
#| fig-cap: "Graphical posterior predictive check by region. Thin red lines indicate model replicates, whereas the blue lines indicate data."
#| label: fig-ppcheck-1

pp_check_fun <- function(outcome, model) {
  path <- str_glue("models/brm-{outcome}-{model}.rds")
  fit <- readRDS(path)
  pp_check(
    fit,
    ndraws = 10,
    type = "dens_overlay",
    resp = "val",
    newdata = fit$data
  )[[1]]
}
pp_check_fun <- memoise(pp_check_fun, cache = cd)

pp_checks <- tibble(
  path = list.files("models/", full.names = TRUE)
) %>% 
  separate(path, c("brm", "outcome", "model"), sep = "-") %>% 
  select(-brm) %>% 
  mutate(model = str_extract(model, "[0-9]")) %>% 
  mutate(pp_check = map2(outcome, model, ~pp_check_fun(.x, .y))) %>% 
  unnest(pp_check)

pp_checks %>%
  slice_sample(prop = .1) %>% 
  ggplot(aes(value, col = is_y, alpha = is_y, group = rep_id)) +
  scale_color_brewer(palette = "Set1") +
  scale_alpha_manual(values = c(.2, 1)) +
  stat_density(
    geom = "line",
    size = .75,
    position = position_identity()
  ) +
  labs(x = "Value", y = "Density") +
  facet_grid2(
    model~outcome,
    scales = "free", independent = "y",
    labeller = as_labeller(function(x) str_replace(x, "_", "\n"))
  ) +
  theme(
    legend.position = "none",
    panel.spacing = unit(3, "pt"),
    axis.title = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  )
```

